ğŸ“Œ Fine-Tuning GPT-4o-mini for Cybersecurity Incident Classification & Solution Generation
ğŸ§  Project Overview

This project demonstrates the domain adaptation of a Large Language Model (LLM) for cybersecurity applications by fine-tuning GPT-4o-mini on a structured incident dataset.

The system is designed to:

Classify cybersecurity incidents based on textual descriptions

Identify attack categories and techniques

Generate concise, actionable remediation steps aligned with Security Operations Center (SOC) workflows

This work explores how lightweight LLMs can be specialized for operational security intelligence without requiring large-scale model retraining.

ğŸ¯ Motivation

Modern organizations generate massive volumes of security alerts, logs, and reports.
Manual analysis is:

Time-consuming

Error-prone

Difficult to scale

Generic LLMs lack contextual understanding of cybersecurity terminology.
Fine-tuning enables the model to learn domain-specific semantics and support analysts with faster, more consistent decision-making.

âš™ï¸ Methodology
1ï¸âƒ£ Data Preparation

Structured cybersecurity dataset containing:

Incident titles / descriptions

Attack categories

MITRE-aligned techniques

Recommended mitigation actions

2ï¸âƒ£ Instructionâ€“Response Transformation

Each record converted into conversational fine-tuning format:

System â†’ SOC analyst role definition
User â†’ Incident description
Assistant â†’ Classification + recommended solution

3ï¸âƒ£ Model Fine-Tuning

Base Model: GPT-4o-mini

Supervised fine-tuning using curated cybersecurity samples

Optimized hyperparameters to ensure stable convergence

4ï¸âƒ£ Evaluation

Performance assessed using:

Classification accuracy trends

BLEU / ROUGE similarity metrics

Qualitative comparison with expert-written solutions

ğŸ“Š Key Outcomes

Demonstrated strong domain adaptation capability

Generated remediation strategies closely aligned with SOC practices

Achieved high semantic similarity to expert responses

Validated feasibility of using compact LLMs for cybersecurity automation

ğŸ› ï¸ Technology Stack
Component	Tools Used
Language	Python
LLM	GPT-4o-mini
Data Processing	Pandas, NumPy
Development	Jupyter Notebook
Evaluation	BLEU, ROUGE Metrics
Workflow	OpenAI Fine-Tuning Pipeline
ğŸ“ Repository Structure
cybersecurity-llm-finetuning/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ Fine_Tuning_notebook.ipynb
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ Project_Report.pdf
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
ğŸ” Environment Setup

Create a .env file locally (do NOT commit it):

OPENAI_API_KEY=your_api_key_here

The notebook reads credentials securely using environment variables.

ğŸš€ Running the Project

Install dependencies:

pip install -r requirements.txt

Launch Jupyter:

jupyter notebook

Execute the fine-tuning workflow inside:

notebooks/Fine_Tuning_notebook.ipynb
ğŸ”¬ Research Contribution

This project shows that lightweight foundation models can be effectively specialized for cybersecurity reasoning tasks, enabling:

Faster incident triage

AI-assisted threat interpretation

Scalable SOC decision support systems

ğŸ“ˆ Future Work

Integration with SIEM platforms for real-time deployment

Multi-turn reasoning for investigation workflows

Explainable AI for analyst trust

Expansion to live threat-intelligence streams

ğŸ‘¤ Author

Kupakwashe T. Mapuranga
M.Tech â€“ Artificial Intelligence & Machine Learning
Focus: Applied AI Systems Â· LLM Fine-Tuning Â· AI for Security & Sustainability
